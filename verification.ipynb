{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9309e5b0",
   "metadata": {},
   "source": [
    "# Verification of micrograd\n",
    "\n",
    "This Notebook verifies that the forward pass (prediction and loss) and backward pass (gradients) of micrograd yield the same result as pytorch.\n",
    "\n",
    "This is done by initializing the same, simple neural network in both framework (same architecture, weights, biases and loss function), and verifying that they output the same prediction, loss and gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1eebe8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import MLP\n",
    "from torch import nn\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb1ced",
   "metadata": {},
   "source": [
    "### Initialize the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "27bf9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the networks to be equal\n",
    "random.seed(42)\n",
    "\n",
    "# Initializing micrograd neural network\n",
    "mlp = MLP(2, [2, 1])\n",
    "\n",
    "# Initializing pytorch neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_tanh_stack = nn.Sequential(\n",
    "            nn.Linear(2, 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_tanh_stack(x)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model = model.double() # Model should have double precision (float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7ec26",
   "metadata": {},
   "source": [
    "### Copy weights and biases from micrograd NN to pytorch NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7e726a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_weights = []\n",
    "nn_biases = []\n",
    "for l in mlp.layers:\n",
    "    layer_weights = []\n",
    "    layer_biases = []\n",
    "    for n in l.neurons:\n",
    "        layer_weights.append([w.data for w in n.w])\n",
    "        layer_biases.append(n.b.data)\n",
    "    nn_weights.append(layer_weights)\n",
    "    nn_biases.append(layer_biases)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.linear_tanh_stack[0].weight.copy_(torch.tensor(nn_weights[0], dtype=torch.float64))\n",
    "    model.linear_tanh_stack[0].bias.copy_(torch.tensor(nn_biases[0], dtype=torch.float64))\n",
    "    model.linear_tanh_stack[2].weight.copy_(torch.tensor(nn_weights[1], dtype=torch.float64))\n",
    "    model.linear_tanh_stack[2].bias.copy_(torch.tensor(nn_biases[1], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a05157",
   "metadata": {},
   "source": [
    "### Verify that weights and biases are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "32474628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micrograd:\n",
      "\tLayer 0 weights: [[0.2788535969157675, -0.9499784895546661], [-0.5535785237023545, 0.4729424283280248]] - biases: [-0.4499413632617615, 0.3533989748458226]\n",
      "\tLayer 1 weights: [[0.7843591354096908, -0.8261223347411677]] - biases: [-0.15615636062945915]\n",
      "torch:\n",
      "\tLayer 0 weights: [[0.2788535969157675, -0.9499784895546661], [-0.5535785237023545, 0.4729424283280248]] - biases: [-0.4499413632617615, 0.3533989748458226]\n",
      "\tLayer 1 weights: [[0.7843591354096908, -0.8261223347411677]] - biases: [-0.15615636062945915]\n"
     ]
    }
   ],
   "source": [
    "print(\"micrograd:\")\n",
    "for i in range(len(nn_weights)):\n",
    "    print(f\"\\tLayer {i} weights: {nn_weights[i]} - biases: {nn_biases[i]}\")\n",
    "\n",
    "print(\"torch:\")\n",
    "torch.set_printoptions(precision=16)  # show up to 16 decimals\n",
    "print(f\"\\tLayer 0 weights: {model.linear_tanh_stack[0].weight.data.tolist()} - biases: {model.linear_tanh_stack[0].bias.data.tolist()}\")\n",
    "print(f\"\\tLayer 1 weights: {model.linear_tanh_stack[2].weight.data.tolist()} - biases: {model.linear_tanh_stack[2].bias.data.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed6884",
   "metadata": {},
   "source": [
    "### Define input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c59f178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "x = [1.0, 0.0]\n",
    "x_tensor = torch.tensor(x, dtype=torch.float64)\n",
    "\n",
    "#  Target\n",
    "y_target = 0.0\n",
    "y_target_tensor = torch.tensor(y_target, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ffa0b",
   "metadata": {},
   "source": [
    "### Predicition (forward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9f9692fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micrograd: \t -0.12519737124741515\n",
      "torch: \t\t -0.12519737124741515\n"
     ]
    }
   ],
   "source": [
    "pred = mlp(x)\n",
    "print(\"micrograd: \\t\", pred.data)\n",
    "\n",
    "torch_pred = model(x_tensor)\n",
    "print(\"torch: \\t\\t\", torch_pred.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d7b89",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f27b0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micrograd: \t 0.01567438176726309\n",
      "torch: \t\t 0.01567438176726309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmolsingh/Kode/micrograd/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "loss = (pred - y_target)**2\n",
    "print(\"micrograd: \\t\", loss.data)\n",
    "\n",
    "torch_loss = loss_fn(torch_pred, y_target_tensor)\n",
    "print(\"torch: \\t\\t\", torch_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebf753",
   "metadata": {},
   "source": [
    "### Backward pass (calculate gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6e7ecf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micrograd:\n",
      "\tLayer 0:\n",
      "\t\tWeight grad ['-0.18777088190078228', '0.0'] - bias grad: -0.18777088190078228\n",
      "\t\tWeight grad ['0.19566825636430066', '0.0'] - bias grad: 0.19566825636430066\n",
      "\tLayer 1:\n",
      "\t\tWeight grad ['0.04176132224435531', '0.04868961513469122'] - bias grad: -0.2464699597084508\n",
      "torch:\n",
      "\tlinear_tanh_stack.0.weight (grad): [[-0.18777088190078228, 0.0], [0.19566825636430066, 0.0]]\n",
      "\tlinear_tanh_stack.0.bias (grad): [-0.18777088190078228, 0.19566825636430066]\n",
      "\tlinear_tanh_stack.2.weight (grad): [[0.04176132224435531, 0.04868961513469123]]\n",
      "\tlinear_tanh_stack.2.bias (grad): [-0.2464699597084508]\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "torch_loss.backward()\n",
    "\n",
    "print(\"micrograd:\")\n",
    "for i in range(len(mlp.layers)):\n",
    "    print(f\"\\tLayer {i}:\")\n",
    "    for n in mlp.layers[i].neurons:\n",
    "        param_list = [str(v.grad) for v in n.w]\n",
    "        print(f\"\\t\\tWeight grad {param_list} - bias grad: {str(n.b.grad)}\")\n",
    "\n",
    "print(\"torch:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"\\t{name} (grad): {param.grad.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
